{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating mixed layer depth  \n",
    "Determine for each grid point for each August the max MLD using density threshold of 0.03 kg/m3 from the 10 m depth value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/intake/source/discovery.py:136: FutureWarning: The drivers ['stac-catalog', 'stac-collection', 'stac-item'] do not specify entry_points and were only discovered via a package scan. This may break in a future release of intake. The packages should be updated.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "import warnings\n",
    "import gcsfs\n",
    "from xhistogram.xarray import histogram\n",
    "import intake\n",
    "import util\n",
    "import gsw\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pangeo-cmip6-ESM Collection with 28657 entries:\n",
       "\t> 10 activity_id(s)\n",
       "\n",
       "\t> 23 institution_id(s)\n",
       "\n",
       "\t> 48 source_id(s)\n",
       "\n",
       "\t> 29 experiment_id(s)\n",
       "\n",
       "\t> 86 member_id(s)\n",
       "\n",
       "\t> 23 table_id(s)\n",
       "\n",
       "\t> 190 variable_id(s)\n",
       "\n",
       "\t> 7 grid_label(s)\n",
       "\n",
       "\t> 28657 zstore(s)\n",
       "\n",
       "\t> 59 dcpp_init_year(s)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if util.is_ncar_host():\n",
    "    col = intake.open_esm_datastore(\"../catalogs/glade-cmip6.json\")\n",
    "else:\n",
    "    col = intake.open_esm_datastore(\"../catalogs/pangeo-cmip6.json\")\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_id</th>\n",
       "      <th>institution_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>table_id</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>grid_label</th>\n",
       "      <th>zstore</th>\n",
       "      <th>dcpp_init_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14574</th>\n",
       "      <td>CMIP</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>historical</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>Omon</td>\n",
       "      <td>so</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/CMIP/NCAR/CESM2/historical/r1i1p1f1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14580</th>\n",
       "      <td>CMIP</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>historical</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>Omon</td>\n",
       "      <td>thetao</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/CMIP/NCAR/CESM2/historical/r1i1p1f1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      activity_id institution_id source_id experiment_id member_id table_id  \\\n",
       "14574        CMIP           NCAR     CESM2    historical  r1i1p1f1     Omon   \n",
       "14580        CMIP           NCAR     CESM2    historical  r1i1p1f1     Omon   \n",
       "\n",
       "      variable_id grid_label  \\\n",
       "14574          so         gn   \n",
       "14580      thetao         gn   \n",
       "\n",
       "                                                  zstore  dcpp_init_year  \n",
       "14574  gs://cmip6/CMIP/NCAR/CESM2/historical/r1i1p1f1...             NaN  \n",
       "14580  gs://cmip6/CMIP/NCAR/CESM2/historical/r1i1p1f1...             NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = col.search(experiment_id=['historical'], institution_id='NCAR', table_id='Omon', member_id='r1i1p1f1', variable_id=['thetao','so','siconc'], grid_label='gn')\n",
    "cat.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 1 group(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['CMIP.NCAR.CESM2.historical.Omon.gn'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_dict = cat.to_dataset_dict(zarr_kwargs={'consolidated': True, 'decode_times': False}, \n",
    "                                cdf_kwargs={'chunks': {}, 'decode_times': False})\n",
    "dset_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (d2: 2, lev: 60, member_id: 1, nlat: 384, nlon: 320, time: 1980, vertices: 4)\n",
      "Coordinates:\n",
      "  * time       (time) float64 6.749e+05 6.749e+05 ... 7.351e+05 7.351e+05\n",
      "  * lev        (lev) float64 500.0 1.5e+03 2.5e+03 ... 5.125e+05 5.375e+05\n",
      "  * nlat       (nlat) int32 1 2 3 4 5 6 7 8 ... 377 378 379 380 381 382 383 384\n",
      "  * nlon       (nlon) int32 1 2 3 4 5 6 7 8 ... 313 314 315 316 317 318 319 320\n",
      "  * member_id  (member_id) <U8 'r1i1p1f1'\n",
      "Dimensions without coordinates: d2, vertices\n",
      "Data variables:\n",
      "    pdens      (member_id, time, lev, nlat, nlon) float64 dask.array<chunksize=(1, 8, 60, 384, 320), meta=np.ndarray>\n",
      "    cthetao    (member_id, time, lev, nlat, nlon) float64 dask.array<chunksize=(1, 8, 60, 384, 320), meta=np.ndarray>\n",
      "    lat_bnds   (nlat, nlon, vertices) float32 dask.array<chunksize=(384, 320, 4), meta=np.ndarray>\n",
      "    lat        (nlat, nlon) float64 dask.array<chunksize=(384, 320), meta=np.ndarray>\n",
      "    lon_bnds   (nlat, nlon, vertices) float32 dask.array<chunksize=(384, 320, 4), meta=np.ndarray>\n",
      "    time_bnds  (time, d2) float64 dask.array<chunksize=(1980, 2), meta=np.ndarray>\n",
      "    lev_bnds   (lev, d2) float32 dask.array<chunksize=(60, 2), meta=np.ndarray>\n",
      "    lon        (nlat, nlon) float64 dask.array<chunksize=(384, 320), meta=np.ndarray>\n",
      "    so         (member_id, time, lev, nlat, nlon) float32 dask.array<chunksize=(1, 10, 60, 384, 320), meta=np.ndarray>\n",
      "    thetao     (member_id, time, lev, nlat, nlon) float32 dask.array<chunksize=(1, 8, 60, 384, 320), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": [
    "for i in dset_dict:\n",
    "    cthetao = xr.apply_ufunc(gsw.CT_from_pt, dset_dict[i].so, dset_dict[i].thetao, dask='parallelized',\n",
    "                                             output_dtypes=[float,]).rename('cthetao').to_dataset() \n",
    "    dset_dict[i] = xr.merge([cthetao, dset_dict[i]])\n",
    "\n",
    "for i in dset_dict:    \n",
    "    pdens=xr.apply_ufunc(gsw.density.sigma0,dset_dict[i].so, dset_dict[i].cthetao, dask='parallelized', \n",
    "                        output_dtypes=[float, ]).rename('pdens').to_dataset()\n",
    "    dset_dict[i] = xr.merge([pdens, dset_dict[i]])\n",
    "    print(dset_dict[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'lev' (lev: 60)>\n",
      "array([5.000000e+00, 1.500000e+01, 2.500000e+01, 3.500000e+01, 4.500000e+01,\n",
      "       5.500000e+01, 6.500000e+01, 7.500000e+01, 8.500000e+01, 9.500000e+01,\n",
      "       1.050000e+02, 1.150000e+02, 1.250000e+02, 1.350000e+02, 1.450000e+02,\n",
      "       1.550000e+02, 1.650984e+02, 1.754790e+02, 1.862913e+02, 1.976603e+02,\n",
      "       2.097114e+02, 2.225783e+02, 2.364088e+02, 2.513702e+02, 2.676542e+02,\n",
      "       2.854837e+02, 3.051192e+02, 3.268680e+02, 3.510935e+02, 3.782276e+02,\n",
      "       4.087846e+02, 4.433777e+02, 4.827367e+02, 5.277280e+02, 5.793729e+02,\n",
      "       6.388626e+02, 7.075633e+02, 7.870025e+02, 8.788252e+02, 9.847059e+02,\n",
      "       1.106204e+03, 1.244567e+03, 1.400497e+03, 1.573946e+03, 1.764003e+03,\n",
      "       1.968944e+03, 2.186457e+03, 2.413972e+03, 2.649001e+03, 2.889385e+03,\n",
      "       3.133405e+03, 3.379793e+03, 3.627670e+03, 3.876452e+03, 4.125768e+03,\n",
      "       4.375392e+03, 4.625190e+03, 4.875083e+03, 5.125028e+03, 5.375000e+03])\n",
      "Coordinates:\n",
      "  * lev      (lev) float64 5.0 15.0 25.0 35.0 ... 4.875e+03 5.125e+03 5.375e+03\n",
      "Attributes:\n",
      "    axis:           Z\n",
      "    bounds:         lev_bnds\n",
      "    positive:       down\n",
      "    standard_name:  olevel\n",
      "    title:          ocean model level\n",
      "    type:           double\n",
      "    units:          m\n"
     ]
    }
   ],
   "source": [
    "# need to find index of depth or lev that is closest to 10m. If units are in centimeters, convert to meters\n",
    "\n",
    "if 'depth' in dset_dict[i]:\n",
    "    dset_dict[i].depth = xr.Dataset.rename({'depth':'lev'})\n",
    "    print(dset_dict[i])\n",
    "if dset_dict[i].lev.units == 'centimeters':\n",
    "    dset_dict[i].lev.values = dset_dict[i].lev.values/100\n",
    "    dset_dict[i].lev.attrs['units'] = 'm'\n",
    "    print(dset_dict[i].lev)\n",
    "\n",
    "# interpolate density data\n",
    "for i in dset_dict:\n",
    "    dsi = dset_dict[i].pdens.interp(lev=np.linspace(0,20,21))\n",
    "    surf_dens = dsi.sel(lev = 10)\n",
    "#     print(surf_dens)\n",
    "#     surf_dens.isel(time=0).plot();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dset_dict:\n",
    "    dens_diff = dset_dict[i].pdens - surf_dens\n",
    "#     print(dens_diff.isel(time=0).min().values)\n",
    "    dens_diff = dens_diff.where(dens_diff > 0.03)\n",
    "#     print(dens_diff.shape)\n",
    "    min_dens_diff = dens_diff.lev.where(dens_diff==dens_diff.min(['lev'])).max(['lev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dens_diff.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = min_dens_diff.isel(member_id=-1, time=slice(-13,-1)).sel(nlon=slice(200,250), nlat=slice(0,80)).mean(['nlon','nlat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dens_diff.isel(time=-1, member_id=-1).isel(nlat=100, nlon=100).min(['lev']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dens_diff.min([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dens_diff.isel(time=-1, member_id=-1)[0,100,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dens_diff.isel(member_id=0, time=-1, nlat=100, nlon=100).min(['lev']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_dict[i].pdens.isel(time=0).max().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.feature as cfeature\n",
    "import numpy.ma as ma\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "for n,i in enumerate(dset_dict):\n",
    "    print(n)\n",
    "    ax = plt.subplot(1,2,n+1,projection=ccrs.SouthPolarStereo())\n",
    "    ax.add_feature(cfeature.LAND,zorder=100,edgecolor='k')\n",
    "    ax.set_extent([0.005, 360,  -90, -50], crs=ccrs.PlateCarree())\n",
    "        \n",
    "\n",
    "    mydata = dset_dict[i].pdens.isel(time=0,lev=0).values[0,:,:]\n",
    "    print(mydata.shape)\n",
    "    mydata = ma.masked_where(dset_dict[i].lat.values>0.,mydata)\n",
    "    print(dset_dict[i].lat.values.shape)\n",
    "    \n",
    "    ax.pcolormesh(dset_dict[i].lat, dset_dict[i].lon, mydata,transform =ccrs.PlateCarree())\n",
    "    #ax.coastlinesmydata()\n",
    "plt.tight_layout()\n",
    "plt.show(); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,i in enumerate(dset_dict):\n",
    "    dset_dict[i].pdens.isel(time=0,lev=0).plot(); plt.show(); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
